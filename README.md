# WikiWhisper
A minimal-size language model fine-tuned on the WikiText-2 dataset using distilgpt2. This project demonstrates how to efficiently train a lightweight, coherent text generator on Wikipedia-style data using Hugging Face Transformers in Google Colab. No UI, no bloat â€” just functional NLP, made simple.
